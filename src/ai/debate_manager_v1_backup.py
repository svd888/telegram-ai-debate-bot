"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–µ–±–∞—Ç–æ–≤ –º–µ–∂–¥—É AI –º–æ–¥–µ–ª—è–º–∏
"""
import uuid
import json
from typing import List, Dict, Optional
from datetime import datetime
from pathlib import Path

from utils import config, log
from ai.models import AIResponse, DebateRound, DebateSession
from ai.openrouter_client import openrouter_client


class DebateManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–º –¥–µ–±–∞—Ç–æ–≤ –º–µ–∂–¥—É AI –º–æ–¥–µ–ª—è–º–∏"""
    
    def __init__(self):
        self.client = openrouter_client
        self.debates_dir = Path(__file__).parent.parent.parent / "data" / "debates"
        self.debates_dir.mkdir(parents=True, exist_ok=True)
    
    async def start_debate(
        self,
        user_id: int,
        question: str,
        mode: str = 'standard',
        model_keys: Optional[List[str]] = None
    ) -> DebateSession:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ–±–∞—Ç—ã
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è Telegram
            question: –í–æ–ø—Ä–æ—Å –¥–ª—è –¥–µ–±–∞—Ç–æ–≤
            mode: –†–µ–∂–∏–º –¥–µ–±–∞—Ç–æ–≤ (quick, standard, deep)
            model_keys: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ)
            
        Returns:
            DebateSession —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        session_id = str(uuid.uuid4())
        debate_mode = config.get_debate_mode(mode)
        
        session = DebateSession(
            session_id=session_id,
            user_id=user_id,
            question=question,
            mode=mode
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ–±–∞—Ç–æ–≤
        if model_keys is None:
            model_keys = list(config.get_all_models().keys())
        
        log.info(
            f"–ù–∞—á–∞–ª–æ –¥–µ–±–∞—Ç–æ–≤ {session_id}: –≤–æ–ø—Ä–æ—Å='{question}', "
            f"—Ä–µ–∂–∏–º={mode}, —Ä–∞—É–Ω–¥–æ–≤={debate_mode.rounds}, –º–æ–¥–µ–ª–∏={model_keys}"
        )
        
        # –†–∞—É–Ω–¥ 1: –ù–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –æ—Ç–≤–µ—Ç—ã
        round_1 = await self._run_initial_round(question, model_keys)
        session.add_round(round_1)
        
        # –†–∞—É–Ω–¥—ã 2-N: –î–µ–±–∞—Ç—ã —Å —É—á–µ—Ç–æ–º –æ—Ç–≤–µ—Ç–æ–≤ –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
        for round_num in range(2, debate_mode.rounds + 1):
            debate_round = await self._run_debate_round(
                question=question,
                round_number=round_num,
                total_rounds=debate_mode.rounds,
                previous_responses=round_1.responses if round_num == 2 else session.rounds[-1].responses,
                model_keys=model_keys
            )
            session.add_round(debate_round)
        
        # –°–∏–Ω—Ç–µ–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        final_answer, final_confidence = await self._synthesize_final_answer(
            question=question,
            session=session
        )
        
        session.complete(final_answer, final_confidence)
        
        # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤
        total_tokens = sum(
            response.tokens_used or 0
            for round_data in session.rounds
            for response in round_data.responses
        )
        session.total_tokens = total_tokens
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–±–∞—Ç—ã
        self._save_debate(session)
        
        log.info(
            f"–î–µ–±–∞—Ç—ã {session_id} –∑–∞–≤–µ—Ä—à–µ–Ω—ã: "
            f"—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={final_confidence}%, —Ç–æ–∫–µ–Ω–æ–≤={total_tokens}"
        )
        
        return session
    
    async def _run_initial_round(
        self,
        question: str,
        model_keys: List[str]
    ) -> DebateRound:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–≤—ã–π —Ä–∞—É–Ω–¥ - –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –æ—Ç–≤–µ—Ç—ã
        
        Args:
            question: –í–æ–ø—Ä–æ—Å
            model_keys: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
            
        Returns:
            DebateRound —Å –æ—Ç–≤–µ—Ç–∞–º–∏
        """
        log.info(f"–†–∞—É–Ω–¥ 1: –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –æ—Ç–≤–µ—Ç—ã –æ—Ç {len(model_keys)} –º–æ–¥–µ–ª–µ–π")
        
        system_prompt = config.get_system_prompt('initial_round')
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ]
        
        responses = await self.client.get_multiple_responses(
            model_keys=model_keys,
            messages=messages
        )
        
        round_data = DebateRound(
            round_number=1,
            responses=responses
        )
        
        log.info(f"–†–∞—É–Ω–¥ 1 –∑–∞–≤–µ—Ä—à–µ–Ω: –ø–æ–ª—É—á–µ–Ω–æ {len(responses)} –æ—Ç–≤–µ—Ç–æ–≤")
        
        return round_data
    
    async def _run_debate_round(
        self,
        question: str,
        round_number: int,
        total_rounds: int,
        previous_responses: List[AIResponse],
        model_keys: List[str]
    ) -> DebateRound:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞—É–Ω–¥ –¥–µ–±–∞—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
        
        Args:
            question: –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å
            round_number: –ù–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ —Ä–∞—É–Ω–¥–∞
            total_rounds: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞—É–Ω–¥–æ–≤
            previous_responses: –û—Ç–≤–µ—Ç—ã –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞—É–Ω–¥–∞
            model_keys: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
            
        Returns:
            DebateRound —Å –æ—Ç–≤–µ—Ç–∞–º–∏
        """
        log.info(f"–†–∞—É–Ω–¥ {round_number}/{total_rounds}: –¥–µ–±–∞—Ç—ã")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –æ—Ç–≤–µ—Ç–∞–º–∏ –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
        other_responses_text = self._format_responses_for_context(previous_responses)
        
        system_prompt = config.get_system_prompt(
            'debate_round',
            round_number=round_number,
            total_rounds=total_rounds,
            question=question,
            other_responses=other_responses_text
        )
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"–ü—Ä–æ–¥–æ–ª–∂–∏ –∞–Ω–∞–ª–∏–∑ –≤–æ–ø—Ä–æ—Å–∞: {question}"}
        ]
        
        responses = await self.client.get_multiple_responses(
            model_keys=model_keys,
            messages=messages
        )
        
        round_data = DebateRound(
            round_number=round_number,
            responses=responses
        )
        
        log.info(f"–†–∞—É–Ω–¥ {round_number} –∑–∞–≤–µ—Ä—à–µ–Ω: –ø–æ–ª—É—á–µ–Ω–æ {len(responses)} –æ—Ç–≤–µ—Ç–æ–≤")
        
        return round_data
    
    async def _synthesize_final_answer(
        self,
        question: str,
        session: DebateSession
    ) -> tuple[str, float]:
        """
        –°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö —Ä–∞—É–Ω–¥–æ–≤ –¥–µ–±–∞—Ç–æ–≤
        
        Args:
            question: –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å
            session: –°–µ—Å—Å–∏—è –¥–µ–±–∞—Ç–æ–≤
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—Ñ–∏–Ω–∞–ª—å–Ω—ã–π_–æ—Ç–≤–µ—Ç, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        """
        log.info("–°–∏–Ω—Ç–µ–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Ç–≤–µ—Ç—ã –∏–∑ –≤—Å–µ—Ö —Ä–∞—É–Ω–¥–æ–≤
        all_responses_text = ""
        for round_data in session.rounds:
            all_responses_text += f"\n\n=== –†–ê–£–ù–î {round_data.round_number} ===\n"
            all_responses_text += self._format_responses_for_context(round_data.responses)
        
        system_prompt = config.get_system_prompt('synthesis')
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"–í–æ–ø—Ä–æ—Å: {question}\n\n–í—Å–µ –æ—Ç–≤–µ—Ç—ã –∏–∑ –¥–µ–±–∞—Ç–æ–≤:{all_responses_text}"}
        ]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–º—É—é –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ (ChatGPT 5.1)
        synthesis_response = await self.client.get_response(
            model_key='chatgpt',
            messages=messages
        )
        
        if synthesis_response:
            final_answer = synthesis_response.content
            final_confidence = synthesis_response.confidence or 85.0
        else:
            # Fallback: –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            last_round = session.rounds[-1]
            best_response = max(
                last_round.responses,
                key=lambda r: r.confidence or 0
            )
            final_answer = best_response.content
            final_confidence = best_response.confidence or 80.0
        
        log.info(f"–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {final_confidence}%")
        
        return final_answer, final_confidence
    
    def _format_responses_for_context(self, responses: List[AIResponse]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        
        Args:
            responses: –°–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—Ç–æ–≤
            
        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        formatted = []
        for response in responses:
            model_config = config.get_model_config(response.model_key)
            color = model_config.color if model_config else "‚ö™"
            
            confidence_text = f" (–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {response.confidence}%)" if response.confidence else ""
            
            formatted.append(
                f"\n{color} **{response.model_name}**{confidence_text}:\n{response.content}"
            )
        
        return "\n".join(formatted)
    
    def _save_debate(self, session: DebateSession):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ–±–∞—Ç—ã –≤ —Ñ–∞–π–ª
        
        Args:
            session: –°–µ—Å—Å–∏—è –¥–µ–±–∞—Ç–æ–≤
        """
        try:
            filename = f"debate_{session.session_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = self.debates_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(session.to_dict(), f, ensure_ascii=False, indent=2, default=str)
            
            log.info(f"–î–µ–±–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–µ–±–∞—Ç–æ–≤: {e}")
    
    def format_debate_for_user(self, session: DebateSession) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ–±–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        
        Args:
            session: –°–µ—Å—Å–∏—è –¥–µ–±–∞—Ç–æ–≤
            
        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        output = f"üéØ **–í–æ–ø—Ä–æ—Å:** {session.question}\n\n"
        output += f"üìä **–†–µ–∂–∏–º:** {session.mode} ({len(session.rounds)} —Ä–∞—É–Ω–¥–æ–≤)\n"
        output += f"‚è± **–í—Ä–µ–º—è:** {(session.completed_at - session.started_at).total_seconds():.1f} —Å–µ–∫\n"
        output += f"üî¢ **–¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ:** {session.total_tokens}\n\n"
        
        output += "=" * 50 + "\n\n"
        output += f"‚úÖ **–§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–í–ï–¢** (–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {session.final_confidence}%)\n\n"
        output += session.final_answer + "\n\n"
        output += "=" * 50 + "\n\n"
        
        output += "üìù **–î–ï–¢–ê–õ–ò –î–ï–ë–ê–¢–û–í:**\n\n"
        
        for round_data in session.rounds:
            output += f"**–†–∞—É–Ω–¥ {round_data.round_number}:**\n\n"
            for response in round_data.responses:
                model_config = config.get_model_config(response.model_key)
                color = model_config.color if model_config else "‚ö™"
                conf = f" ({response.confidence}%)" if response.confidence else ""
                
                output += f"{color} **{response.model_name}**{conf}:\n"
                output += f"{response.content[:300]}...\n\n"
        
        return output


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞
debate_manager = DebateManager()
